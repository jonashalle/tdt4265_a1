{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Report\n",
    "\n",
    "##### By Jonas Halle and Alexander Rambech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1a)\n",
    "\n",
    "From the equations in the task, we have that:\n",
    "$\\alpha \\frac{\\partial C}{\\partial w_{ji}} = \\alpha \\frac{\\partial C}{\\partial z_{j}} \\frac{\\partial z_j}{\\partial w_{ji}}$, where $\\frac{\\partial C}{\\partial z_{j}} = \\delta_j$ and $\\frac{\\partial z_j}{\\partial w_{ji}} = \\frac{\\partial}{\\partial w_{ji}} (x_i \\omega_{ji} + b_j) = x_i$ \n",
    "\n",
    "Since $\\alpha \\frac{\\partial C}{\\partial w_{ji}} = \\alpha \\delta_j x_i$ we have that:\n",
    "\n",
    "$w_{ji} = w_{ji} - \\alpha \\frac{\\partial C}{\\partial w_{ji}} = w_{ji} - \\alpha \\delta x_i$\n",
    "\n",
    "For the other term we have that $\\delta_j = \\frac{\\partial C}{\\partial z_j} = \\sum_k \\frac{\\partial C}{\\partial z_k} \\frac{\\partial z_k}{\\partial z_j} = \\sum_k \\delta_k \\frac{\\partial C}{\\partial z_j}$\n",
    "\n",
    "where $z_k = \\sum_j \\omega_{kj} f(z_j) + b_k$ which yield $\\frac{\\partial z_k}{\\partial z_j} = \\omega_{kj} f'(z_j)$\n",
    "\n",
    "We then have $\\delta_j = \\sum_k \\delta_k \\omega_{kj} f'(z_j) = f'(z_j) \\sum_k \\delta_k \\omega_{kj}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1b)\n",
    "\n",
    "We have that the weight matrix for a given layer $l$ is given by $\\omega^l$. Hence the update rules for the different layers are given by:\n",
    "\n",
    "$\\omega^1 = \\omega^1 - \\alpha \\nabla_x \\frac{\\partial C}{\\partial w^1}$\n",
    "\n",
    "and\n",
    "\n",
    "$\\omega^2 = \\omega^2 - \\alpha \\nabla_x \\frac{\\partial C}{\\partial w^2}$,\n",
    "\n",
    "respectivley."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2a)\n",
    "\n",
    "The mean is $33.5527$ and the standard deviation is $78.8755$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b)\n",
    "\n",
    "This can be seen in the code provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](2c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "\n",
    "The total number of parameters, meaning weights and biases, for this network is $785 \\cdot 64 + 64 \\cdot 10 = 50880$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3a)\n",
    "\n",
    "\n",
    "![](3a_terminal.jpg)\n",
    "\n",
    "![](figure_3a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3b)\n",
    "\n",
    "\n",
    "![](3b_terminal.jpg)\n",
    "\n",
    "![](figure_3b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3c)\n",
    "\n",
    "![](3c_terminal.jpg)\n",
    "\n",
    "![](figure_3c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figure_3c_comparing_accuracy.png)\n",
    "\n",
    "![](figure_3c_comparing_loss.png)\n",
    "\n",
    "by normalizing the weights we reduced training loss and validation loss.\n",
    "and got a better accuracy \n",
    "The performance in terms of convergence speed is only slightly improved from task 2. \n",
    "this can be seen in figure().\n",
    "\n",
    "The paper handed out states that symetric sigmoids often converge faster than the standard logistic function.\n",
    "by only adding the improved sigmoid, the convergence speed decreases with 30%, \n",
    "however the loss and accuracy performance is not that good.\n",
    "However, in terms of loss, the result is worse than for only normalized weights.\n",
    "\n",
    "When the improved sigmoid and normalized weights are combined,\n",
    "the convergence speed drops with 50% while getting good results for loss and accuracy.\n",
    "\n",
    "The idea of adding momentum is to avoid getting stuck in local minimums\n",
    "When adding momentum the convergence speed were yet again reduced. \n",
    "while the loss and accuracy is still good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "A smaller amount of nodes in a network means less sums to be calculated and thereby less information that can be stored. By having a larger network it is easier to make a model that fits the problem better and the training steos will most likely be fewer as well. That being said, the number of operations done in a single pass through the network will be greater for larger networks, the traning time will therefore not necessarily decrease with a larger amount of nodes in a layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "Most was said in 4a), but it can be seen in the differences between the two plots that there are less training steps needed for making an adequate model with $128$ nodes in the hidden layer rather than $32$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "\n",
    "The code provided in task2a.py runs as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "\n",
    "\n",
    "![](Figure_4_3L.png)\n",
    "There are $51300$ parameters in this three layer neural network\n",
    "\n",
    "\n",
    "![](Figure_4_2L.png)\n",
    "\n",
    "There are $50880$ parameters in this two layer neural network\n",
    "\n",
    "By comparing the plots they seem quite equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "\n",
    "![](figure_4_10L.png)\n",
    "\n",
    "Here we see that using $10$ layers with 64 neurons per layer gives a worse result in 15000 epochs."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4022bad56c1407a10084333ca250d48137bd5bed1779c224b7cda5f37046cf60"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
