{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2c87f46",
   "metadata": {},
   "source": [
    "# Assignment 3 Group 116\n",
    "\n",
    "##### By Jonas Halle and Alexander Rambech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c11172",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967454a6",
   "metadata": {},
   "source": [
    "### Task 1a)\n",
    "\n",
    "We choose to do the convolutions using 1 layer of zero padding around the edge of the original image and utilizing a stride length of $S = 1$. This results in the $3 \\times 5$ image:\n",
    "\n",
    "$ \\begin{bmatrix}\n",
    "2 & -1 & 11 & -2 & -13 \\\\\n",
    "10 & -4 & 8 & 2 & -18 \\\\\n",
    "14 & -1 & -5 & 6 & 9 \n",
    "\\end{bmatrix}  $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede190c",
   "metadata": {},
   "source": [
    "### Task 1b)\n",
    "\n",
    "Translational variations are hard to pick up on by normal neural nets, because they don't have the spatial link needed to recognize that the subject of the picture can be in different locations in the frame. CNNs use can use kernel convolutions to check for different features in an image and thereby finding the subject in the image regardless of position in the frame. These features are found in the convolutional layers of the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b204f958",
   "metadata": {},
   "source": [
    "### Task 1c)\n",
    "\n",
    "You would need $2$ layers of padding so that the center pixel of the kernel reaches the outer edges of the input image. Meaning $P = 2$. This can also be checked using the equation \n",
    "\n",
    "$W_2 = \\frac{W_1 - F + 2P}{S}+1$, \n",
    "\n",
    "where $W_2$ is the width of the output layer, $W_1$ is the width of the input layer, $F$ is the size of the square kernel, $S$ is the stride length and $P$ is the padding. Since the goal is that the ouput layer has the same width as the input layer, meaning $W_2 = W_1$ and $S = 1$, the equation for $P$ can be written as:\n",
    "\n",
    "$P = F - 1 = 3 - 1 = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0661a2",
   "metadata": {},
   "source": [
    "### 1d)\n",
    "\n",
    "We have that $W_2 = \\frac{W_1 - F + 2P}{s} + 1 \\implies F = W_1 + 2P - \\frac{W_2}{s} + 1 = 512 + 2 \\cdot 0 - \\frac{504}{1} = 9$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592d953d",
   "metadata": {},
   "source": [
    "### 1e)\n",
    "\n",
    "$W_2 = \\frac{W_1 - F + 2P}{S} + 1 = \\frac{504 - 2 + 2 \\cdot 0}{2} + 1 = 252$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360071c",
   "metadata": {},
   "source": [
    "### 1f)\n",
    "\n",
    "$W_2 = \\frac{252 - 3 + 2 \\cdot 0}{1} + 1 = 250$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e0621",
   "metadata": {},
   "source": [
    "### 1g)\n",
    "\n",
    "Since the input is a square RGB image of size $32$, we have $3$ channels and thereby an input of size $32 \\times 32 \\times 3$. This means that the $5 \\times 5$ convolutional moving with a stride of $S = 1$ with padding $P = 2$ makes a new layer of the exact same size. \n",
    "\n",
    "The number of parameters in the first convolutional layer is given by the size of the kernel, which are the weights, the number of channels pluss the bias. Times this with the number of filters and we have the number of parameters. The number of parameters in the first layer is thereby given by:\n",
    "\n",
    "$((5 \\cdot 5 \\cdot 3) + 1 ) \\cdot 32 = 2,432$\n",
    "\n",
    "Since the Max-Pooling layer only shrinks the dimension of a channel itself, but not the number of feature maps, the pooling layer has no effect on the amound of parameters in the network. \n",
    "\n",
    "To find the number of parameters for the next layers, we can use the same $((F \\cdot F \\cdot D_1) + b) \\cdot D_2 = N$ formula as above, where $F$ is the size of the kernel, $b$ is the number of biases, $D_1$ is the number of features in the previous layer and $D_2$ is the number of features in the next layer. For the two next convolutional layers this is:\n",
    "\n",
    "$((5 \\cdot 5 \\cdot 32) + 1) \\cdot 64 = 51,264$\n",
    "\n",
    "$((5 \\cdot 5 \\cdot 64) + 1) \\cdot 128 = 204,928$\n",
    "\n",
    "The width of the input channels is $W_i = 32$ and is halfed with each pooling layer, when it's time to flatten after the last pooling, the dimensions of each feature map is $4 \\times 4$. This yields:\n",
    "\n",
    "$((4 \\cdot 4 \\cdot 128) + 1) \\cdot 64 = 131,136$\n",
    "\n",
    "The number of parameters in the last layer is simply given by:\n",
    "\n",
    "$(64 + 1) \\cdot 10 = 650\n",
    "\n",
    "This gives a total parameters of: \n",
    "\n",
    "$2,432 + 51,264 + 204928 + 131,136 + 650 = 390,410$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a176581",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaee0bd",
   "metadata": {},
   "source": [
    "### Task 2a)\n",
    "\n",
    "Early stopping kicks in before epoch 10 and we reach a validation and test accuracy north of 70%, which we regard as pretty good given that we have not started tuning or messing with different techniques for making the CNN better.\n",
    "\n",
    "![](2a_fig_with_validation_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af63ce4",
   "metadata": {},
   "source": [
    "### Task 2b)\n",
    "\n",
    "Final validation and test accuracies are 73.4% and 72.9%, respectivley.\n",
    "\n",
    "![](2b_snipp.png)\n",
    "\n",
    "![](2b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c1324",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839ef48",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
